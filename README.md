# 🧠 LLM Response Validator

A lightweight Python-based testing framework to evaluate and validate the quality of responses generated by Large Language Models (LLMs) like OpenAI's GPT using semantic similarity scoring.

---

## 🚀 Features

- ✅ Automated testing of LLM-generated responses
- ✅ Semantic similarity scoring using `sentence-transformers`
- ✅ Prompt/expected-answer pairs stored in `prompts.json`
- ✅ Simple and extensible testing using `pytest`
- ✅ Secure API key management via `.env`

---

## 🛠️ Tech Stack

- Python 3.9+
- OpenAI API (GPT-3.5-Turbo)
- Sentence-Transformers (`all-MiniLM-L6-v2`)
- Pytest
- Python-dotenv

---

## 📁 Project Structure

```
LLM-response-validator/
├── validator.py         # Main script to run validation
├── test_validator.py    # Pytest-based test cases
├── prompts.json         # Prompt-answer dataset
├── utils.py             # Similarity scoring logic
├── .env                 # Stores OpenAI API Key (not committed)
└── README.md
```

---

## ⚙️ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/jeevan-v8/LLM_response_validator.git
cd LLM-response-validator
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

> If you don't have `requirements.txt`, install manually:
```bash
pip install openai python-dotenv sentence-transformers torch pytest
```

### 3. Add your OpenAI API key

Create a `.env` file:

```env
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxx
```

---

## 🧪 Run the Validator

### Run manually:

```bash
python3 validator.py
```

### Run automated tests with Pytest:

```bash
python3 -m pytest -s
```

---

## 🧾 Sample `prompts.json`

```json
[
  {
    "prompt": "What is the capital of France?",
    "expected_answer": "Paris"
  },
  {
    "prompt": "Who wrote the play Romeo and Juliet?",
    "expected_answer": "William Shakespeare"
  }
]
```

---

## 📊 Output Example

```
Prompt: What is the capital of France?
Expected: Paris
Actual: Paris is the capital of France.
Similarity Score: 0.91
```

---

## 📌 TODOs (Optional Enhancements)

- [ ] Save failed test logs to a file
- [ ] Generate HTML or CSV report
- [ ] Add CLI for dynamic prompt testing

---

## 👤 Author

Jeevan Kumar R  
Feel free to connect or suggest improvements!

---

## 🛡️ License

MIT License